from datetime import datetime
PROJECT_ID = "<your-gcp-project-id>"
REGION = "us-central1"
BUCKET_NAME = "<your-gcs-bucket-name>"
BUCKET_URI = f"gs://{BUCKET_NAME}"
AUTH_KEY = "<your_abs_path>/artifacts/creds.json" #change <your_abs_path>
SERVICE_ACCOUNT = "<your_service_account>.gserviceaccount.com"
IMPORT_FILE = "bq://sara-vertex-demos.beans_demo.large_dataset"  # do not change
BQ_TABLE = "sara-vertex-demos.beans_demo.large_dataset" # do not change
TARGET = "Class" # do not change
BQ_MODEL_NAME = "benas_auto_ml_model"
MODEL_DIR = BUCKET_URI + "/bq_automl_model"
DATASET_NAME = "bqml_kfp_automl_beans"  # Dataset names cannot contain spaces or special characters such as -, &, @, or %.
PIPELINE_ROOT = f"{BUCKET_URI}/bq_query"
PIPELINE_NAME = "bq-beans-automl"
TEMPLATE_PATH = "artifacts/pipeline_beans.json" # you can give any name to .json file
TIMESTAMP = datetime.now().strftime("%Y%m%d%H%M%S")
MACHINE_TYPE = "n1-standard-2"
NUM_TRIALS = 2
MAX_REPLICA_COUNT = 2
MIN_REPLICA_COUNT = 1